---
title: "Analysis Grid Search and Feature Importance"
author: "MochiBear.Hei"
date: "04.06.2025"
format:
  html:
    toc: true
    toc-location: left
    embed-resources: true
    page-layout: full
    html-math-method: katex
editor: source
---

```{css, echo = F}
body{
  font-family: Helvetica;
  font-size: 16pt;
  max-width: 1000px;
  margin: auto;
  margin-left:310px;
}
pre{
  font-size: 14px;
}
/* Headers */
h1{
    font-size: 24pt;
  }
h1,h2{
    font-size: 20pt;
  }
h3,h4,h5,h6{
  font-size: 18pt;
}
#TOC {
  position: fixed;
  left: 0;
  top: 0;
  width: 300px;
  height: 100%;
  overflow:auto;
}
```

```{r setup,suppressPackageStartupMessages= TRUE}
#| include: false
#| message: false
#| warning: false
#| results: hide
knitr::opts_chunk$set(echo = TRUE, dpi = 300)

# Data manipulation
library(dplyr)
library(tidyr)

#models
library(caret)
library(xgboost)

# Plotting
library(ggplot2)
library(viridis)      

# Utilities
library(knitr)


```

# Load
## ID list
```{r}
##list of people to include in analysis analysis_subids.csv
subids <- read.csv("/Users/maggieheimvik/Desktop/GitHub/masters_thesis/Data/ocd/subids.csv") 
```

## MRI
```{r}
mri <- read.csv("/Users/maggieheimvik/Desktop/GitHub/masters_thesis/Data/ocd/mri.csv") %>%
  select (-smri_vol_scs_lesionlh, -smri_vol_scs_lesionrh, -smri_vol_scs_intracranialv) %>% #removed these columns because they have 4897 NA each;   
  distinct(src_subject_id, .keep_all = TRUE)  

full_dat <- mri[mri$src_subject_id %in% subids$src_subject_id, ]
```

## BPM
```{r}
bpm <- read.csv("/Users/maggieheimvik/Desktop/GitHub/masters_thesis/Data/core/mental-health/mh_y_bpm.csv") %>%
  filter(eventname == "2_year_follow_up_y_arm_1") %>%
  select(src_subject_id, bpm_y_scr_internal_t, bpm_y_scr_external_t) %>%
  distinct(src_subject_id, .keep_all = TRUE) %>% #remove duplicates
  mutate(across(c(bpm_y_scr_internal_t, bpm_y_scr_external_t), ~ as.numeric(scale(.)))) #standardize

# merge
full_dat <- inner_join(full_dat, bpm, by = "src_subject_id")
```
## CBCL
```{r}
cbcl <- read.csv("/Users/maggieheimvik/Desktop/LCBC/Data/ABCD/core/mental-health/mh_p_cbcl.csv") %>%
  filter(eventname == "2_year_follow_up_y_arm_1") %>%
  select(
    src_subject_id,cbcl_scr_syn_internal_t, cbcl_scr_syn_external_t
  ) %>%
  distinct(src_subject_id, .keep_all = TRUE) %>% # remove duplicates
  mutate(across(c(cbcl_scr_syn_internal_t, cbcl_scr_syn_external_t), ~ as.numeric(scale(.)))) # standardize scores

# merge
full_dat <- inner_join(full_dat, cbcl, by = "src_subject_id")
```

# Handle NA
```{r}
na_counts <- colSums(is.na(full_dat))
na_counts[na_counts > 0]  # print only columns with NA values


# mean imputation: 
full_dat <- full_dat %>%
  mutate(across(c(mrisdp_508, mrisdp_527, mrisdp_567, mrisdp_582, mrisdp_601, mrisdp_602, mrisdp_603, mrisdp_604),
                ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)))

```



# MODELS
## xg(cbcl_internal)

# Split data
```{r}

# Ensure that your target variable is a factor (if it's not already)
full_dat$cbcl_scr_syn_internal_t <- as.factor(full_dat$cbcl_scr_syn_internal_t)

# Create stratified train/test split
set.seed(123)

splitIndex <- createDataPartition(full_dat$cbcl_scr_syn_internal_t, p = 0.8, list = FALSE)

train_data <- full_dat[splitIndex, ]
test_data <- full_dat[-splitIndex, ]
```

```{r}
set.seed(1)

# Define target and predictors
target <- "cbcl_scr_syn_internal_t"
predictors <- colnames(full_dat)[!colnames(full_dat) %in% c("src_subject_id", "bpm_y_scr_internal_t", "bpm_y_scr_external_t", "cbcl_scr_syn_external_t", target)]

# model matrix 
X_train <- train_data[, predictors, drop = FALSE]
X_test <- test_data[, predictors, drop = FALSE]

# Target variable needs to be a vector
cbcl_scr_syn_internal_t_vector <- as.vector(train_data[[target]])

#make matrix
dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = cbcl_scr_syn_internal_t_vector)
dtest <- xgb.DMatrix(data = as.matrix(X_test), label = y_test)

# Define the parameter grid for hyperparameter tuning
param_grid <- expand.grid(
  nrounds = c(50, 100),       # Number of boosting rounds
  max_depth = c(2, 7),        # Maximum depth of a tree
  min_child_weight = c(1, 2), # Minimum sum of instance weight (hessian) needed in a child
  eta = c(0.05, 0.1),         # Learning rate
  gamma = c(0.1, 1),          # Minimum loss reduction
  subsample = c(0.6, 0.8),    # Subsample ratio of training instances
  colsample_bytree = c(0.6, 0.8) # Subsample ratio of columns when constructing each tree
)

# Display the structure to confirm multiple combinations
str(param_grid)

# Set up cross-validation controls for regression
train_control <- trainControl(
  method = "cv",              # Use cross-validation
  number = 5,                 # 5-fold cross-validation
  verboseIter = TRUE          # Print training progress
)

# Train the model
model_cbcl_i <- train(
  x = X_train,                     # Training features
  y = cbcl_scr_syn_internal_t_vector, # Target variable
  method = "xgbtree",              # Use XGBoost for regression
  tuneGrid = param_grid,           # Expanded parameter grid for tuning
  trControl = train_control,       # Train control setup
  metric = "RMSE"                  # Evaluation metric for regression
)

# Print the best tuning parameters found
print(model_cbcl_i$bestTune)

```

### Results
#### Tuning
```{r}
results_df <- model_cbcl_i$results
print(head(results_df))

results_df$model <- "CBCL"
write.csv(results_df, "results_cbcl_i.csv", row.names = FALSE)
```


#### Post resample evaluation
```{r}
# Make predictions with the trained model on the test data
preds <- predict(model_cbcl_i, newdata = X_test)

# Evaluate using caret's postResample function
evaluation <- postResample(preds, y_test)

# Print evaluation results
print(evaluation)

# Combine predicted and actual values into a data frame
results <- data.frame(
  Actual = y_test,
  Predicted = preds
)                         

# Save the results to a CSV file
write.csv(results, file = "/Users/maggieheimvik/Desktop/GitHub/masters_thesis/Data/ocd/cbcl_i_predicted_vs_actual.csv", row.names = FALSE)
```

#### Feature Importance
```{r}
# Final fitted model
final_model <- model_cbcl_i$finalModel

# Extract feature importance
importance_matrix <- xgb.importance(model = final_model)

# Now plot the feature importance
p <- xgb.plot.importance(
  importance_matrix,
  top_n = 10,
  xlab = "Feature Importance",
  main = "Important Features in Predicting CBCL Internalizing"
)

##############################################################################################Save

# Get importance
importance_matrix <- xgb.importance(model = final_model)

write.csv(importance_matrix, "/Users/maggieheimvik/Desktop/GitHub/masters_thesis/Data/ocd/importance_cbcl_i.csv", row.names = FALSE)

```


## xg(bpm_internal)
```{r}
set.seed(1)

target <- "bpm_y_scr_internal_t"  
predictors <- colnames(full_dat)[!colnames(full_dat) %in% c("src_subject_id","cbcl_scr_syn_internal_t", "bpm_y_scr_external_t",  "cbcl_scr_syn_external_t", target)]  

set.seed(1)

X_train <- train_data[, predictors, drop = FALSE]

bpm_y_scr_internal_t_vector <- as.vector(train_data[[target]])

#make matrix
dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = bpm_y_scr_internal_t_vector)

# Prepare test data
X_test <- test_data[, predictors, drop = FALSE]
y_test <- as.vector(test_data[[target]])

# Convert the test data to a DMatrix object
dtest <- xgb.DMatrix(data = as.matrix(X_test), label = y_test)


param_grid <- expand.grid(
  nrounds = c(50, 100),       
  max_depth = c(2, 7),        
  min_child_weight = c(1, 2), 
  eta = c(0.05, 0.1),         
  gamma = c(0.1, 1),          
  subsample = c(0.6, 0.8),    
  colsample_bytree = c(0.6, 0.8) 
)

#confirm
str(param_grid)

# CV controls
train_control <- trainControl(
  method = "cv",              
  number = 5,                 
  verboseIter = TRUE          
)

# Train the model
model_bpm_i <- train(
  x = X_train,                     
  y = bpm_y_scr_internal_t_vector, 
  method = "xgbTree",              
  tuneGrid = param_grid,           
  trControl = train_control,       
  metric = "RMSE"                  
)

# print the best 
print(model_bpm_i$bestTune)



```

####Tuning
```{r}
results_df <- model_bpm_i$results
print(head(results_df))

results_df$model <- "BPM"
write.csv(results_df, "results_bpm_i.csv", row.names = FALSE)
```

####Post resample evaluation
```{r}
# Make predictions with the trained model on the test data
preds <- predict(model_bpm_i, newdata = X_test)

# Evaluate using caret's postResample function
evaluation <- postResample(preds, y_test)

# Print evaluation results
print(evaluation)

# Combine predicted and actual values into a data frame
results <- data.frame(
  Actual = y_test,
  Predicted = preds
)

# Save the results to a CSV file
write.csv(results, file = "/Users/maggieheimvik/Desktop/GitHub/masters_thesis/Data/ocd/bpm_i_predicted_vs_actual.csv", row.names = FALSE)
```

#### Feature Importance
```{r}

# Final fitted model
final_model <- model_bpm_i$finalModel

# Extract feature importance
importance_matrix <- xgb.importance(model = final_model)


#write.csv(importance_matrix, "/Users/maggieheimvik/Desktop/GitHub/masters_thesis/Data/ocd/importance_bpm_i.csv", row.names = FALSE)

# Now plot the feature importance
p <- xgb.plot.importance(
  importance_matrix,
  top_n = 10,
  xlab = "Feature Importance",
  main = "Important Features in Predicting BPM Internalizing"
)

#################

write.csv(importance_matrix, "/Users/maggieheimvik/Desktop/GitHub/masters_thesis/Data/ocd/importance_bpm_i.csv", row.names = FALSE)

```


## xg(cbcl_external)
```{r}
set.seed(1)

target <- "cbcl_scr_syn_external_t"  
predictors <- colnames(full_dat)[!colnames(full_dat) %in% c("src_subject_id","cbcl_scr_syn_internal_t", "bpm_y_scr_external_t",  "bpm_y_scr_internal_t", target)]  

set.seed(1)

X_train <- train_data[, predictors, drop = FALSE]

cbcl_scr_syn_external_t_vector <- as.vector(train_data[[target]])

#make matrix
dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = cbcl_scr_syn_external_t_vector)

# Prepare test data
X_test <- test_data[, predictors, drop = FALSE]
y_test <- as.vector(test_data[[target]])

# Convert the test data to a DMatrix object
dtest <- xgb.DMatrix(data = as.matrix(X_test), label = y_test)


param_grid <- expand.grid(
  nrounds = c(50, 100),       
  max_depth = c(2, 7),        
  min_child_weight = c(1, 2), 
  eta = c(0.05, 0.1),         
  gamma = c(0.1, 1),          
  subsample = c(0.6, 0.8),    
  colsample_bytree = c(0.6, 0.8) 
)

#confirm
str(param_grid)

# CV controls
train_control <- trainControl(
  method = "cv",              
  number = 5,                 
  verboseIter = TRUE          
)

# Train the model
model_cbcl_e <- train(
  x = X_train,                     
  y = cbcl_scr_syn_external_t_vector, 
  method = "xgbTree",              
  tuneGrid = param_grid,           
  trControl = train_control,       
  metric = "RMSE"                  
)

# print the best 
print(model_cbcl_e$bestTune)

```

### Results
#### Tuning
```{r}
results_df <- model_cbcl_e$results
print(head(results_df))

results_df$model <- "CBCL"
write.csv(results_df, "results_cbcl_e.csv", row.names = FALSE)

```


#### Post resample evaluation
```{r}
# Make predictions with the trained model on the test data
preds <- predict(model_cbcl_e, newdata = X_test)

# Evaluate using caret's postResample function
evaluation <- postResample(preds, y_test)

# Print evaluation results
print(evaluation)

# Combine predicted and actual values into a data frame
results <- data.frame(
  Actual = y_test,
  Predicted = preds
)

# Save the results to a CSV file
write.csv(results, file = "/Users/maggieheimvik/Desktop/GitHub/masters_thesis/Data/ocd/cbcl_e_predicted_vs_actual.csv", row.names = FALSE)
```

#### Feature Importance
```{r}
# Final fitted model
final_model <- model_cbcl_e$finalModel

# Extract feature importance
importance_matrix <- xgb.importance(model = final_model)

# Now plot the feature importance
p <- xgb.plot.importance(
  importance_matrix,
  top_n = 10,
  xlab = "Feature Importance",
  main = "Important Features in Predicting CBCL externalizing"
)

##############################################################################################Save

write.csv(importance_matrix, "/Users/maggieheimvik/Desktop/GitHub/masters_thesis/Data/ocd/importance_cbcl_e.csv", row.names = FALSE)

```

## xg(bpm_external)
```{r}
set.seed(1)

# Define target and predictors
target <- "bpm_y_scr_external_t"
predictors <- colnames(full_dat)[!colnames(full_dat) %in% c("src_subject_id", "bpm_y_scr_internal_t", "cbcl_scr_syn_external_t", "cbcl_scr_syn_internal_t", target)]

# Remove the target variable from the feature set
X_train <- train_data[, predictors, drop = FALSE] ############################### Change variable

# Target variable needs to be a vector
bpm_y_scr_external_t_vector <- as.vector(train_data[[target]]) ################## Change variable

# Convert to a DMatrix object for XGBoost
dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = bpm_y_scr_external_t_vector)

# Prepare test data
X_test <- test_data[, predictors, drop = FALSE]
y_test <- as.vector(test_data[[target]])

# Convert to a DMatrix object
dtest <- xgb.DMatrix(data = as.matrix(X_test), label = y_test)

# Define the parameter grid 
param_grid <- expand.grid(
  nrounds = c(50, 100),       
  max_depth = c(2, 7),        
  min_child_weight = c(1, 2), 
  eta = c(0.05, 0.1),         
  gamma = c(0.1, 1),          
  subsample = c(0.6, 0.8),    
  colsample_bytree = c(0.6, 0.8) 
)

#check
str(param_grid)

# CV 
train_control <- trainControl(
  method = "cv",              
  number = 5,                 
  verboseIter = TRUE          
)
model_bpm_e <- train(
  x = X_train,                    
  y = bpm_y_scr_external_t_vector, 
  method = "xgbTree",             
  tuneGrid = param_grid,          
  trControl = train_control,      
  metric = "RMSE"                 
)  # Close the train function with this parenthesis

# Print the best tuning parameters found
print(model_bpm_e$bestTune)

```

### Results
#### Tuning
```{r}
results_df <- model_bpm_e$results
print(head(results_df))

results_df$model <- "BPM"
write.csv(results_df, "results_bpm_e.csv", row.names = FALSE)

```


#### Post resample evaluation
```{r}
# Make predictions with the trained model on the test data
preds <- predict(model_bpm_e, newdata = X_test)

# Evaluate using caret's postResample function
evaluation <- postResample(preds, y_test)

# Print evaluation results
print(evaluation)

# Combine predicted and actual values into a data frame
results <- data.frame(
  Actual = y_test,
  Predicted = preds
)

# Save the results to a CSV file
write.csv(results, file = "/Users/maggieheimvik/Desktop/GitHub/masters_thesis/Data/ocd/bpm_e_predicted_vs_actual.csv", row.names = FALSE)

```


#### Feature Importance
```{r}
# Final fitted model
final_model <- model_bpm_e$finalModel

# Extract feature importance
importance_matrix <- xgb.importance(model = final_model)

# Now plot the feature importance
p <- xgb.plot.importance(
  importance_matrix,
  top_n = 10,
  xlab = "Feature Importance",
  main = "Important Features in Predicting BPM externalizing"
)

##############################################################################################Save
top10_features <- importance_matrix[1:10, ]
print(top10_features)


write.csv(importance_matrix, "/Users/maggieheimvik/Desktop/GitHub/masters_thesis/Data/ocd/importance_bpm_e.csv", row.names = FALSE)

```
